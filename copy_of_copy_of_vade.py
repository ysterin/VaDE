# -*- coding: utf-8 -*-
"""Copy of Copy of VaDE.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14a1m2hcOYM2oJTFXki0U-TdGXKk9SC-p
"""

import os
os.environ['CUDA_LAUNCH_BLOCKING'] = '1'
import numpy as np
import torch
from torch.utils.data import DataLoader, Dataset
from torch import nn, distributions
from torch.nn import functional as F
from torch import distributions as D
from torchvision.datasets import MNIST, FashionMNIST
from torchvision import transforms
import pytorch_lightning as pl
from matplotlib import pyplot as plt
from torch.distributions import Normal, Laplace, kl_divergence, kl, Categorical
import math
from sklearn.cluster import KMeans
from sklearn.mixture import GaussianMixture
from sklearn import metrics

from time import time
from contextlib import contextmanager

@contextmanager
def timethis(label):
    t0 = time()
    yield
    elapsed = time() - t0
    print(f"{label} took {elapsed} seconds")

transform = transforms.Compose([transforms.ToTensor(), 
                                transforms.Lambda(lambda x: torch.flatten(x))])

def get_autoencoder(n_neurons, batch_norm=True):
    enc_layers = len(n_neurons)
    layer_dims = n_neurons + n_neurons[-2::-1]
    n_layers = len(layer_dims)
    return nn.Sequential(*[nn.Sequential(nn.Linear(layer_dims[i], layer_dims[i+1]),
                                         nn.Identity() \
                                            if i+2 == enc_layers or i+2 == n_layers or not batch_norm \
                                            else nn.BatchNorm1d(layer_dims[i+1]),
                                         nn.Identity() \
                                            if i+2 == enc_layers or i+2 == n_layers \
                                            else nn.ELU()) \
                           for i in range(n_layers - 1)])

def get_encoder_decoder(n_neurons, batch_norm=True):
    n_layers = len(n_neurons) - 1
    encoder_layers = [nn.Sequential(nn.Linear(n_neurons[i], n_neurons[i+1]),
                                    nn.ReLU(),
                                    nn.BatchNorm1d(n_neurons[i+1]) if batch_norm else nn.Identity()) for i in range(n_layers - 1)]
    encoder_layers.append(nn.Linear(n_neurons[-2], n_neurons[-1]))
    n_neurons = n_neurons[::-1]
    decoder_layers = [nn.Sequential(nn.Linear(n_neurons[i], n_neurons[i+1]),
                                    nn.ReLU(),
                                    nn.BatchNorm1d(n_neurons[i+1]) if batch_norm else nn.Identity()) for i in range(n_layers - 1)]
    decoder_layers.append(nn.Sequential(nn.Linear(n_neurons[-2], n_neurons[-1]), nn.Sigmoid()))
    return nn.Sequential(*encoder_layers), nn.Sequential(*decoder_layers)

class SimpleAutoencoder(pl.LightningModule):
    def __init__(self, n_neurons=[784, 512, 256, 10], lr=1e-3, batch_norm=True):
        super(SimpleAutoencoder, self).__init__()
        self.hparams = {'lr': lr}
        self.encoder, self.decoder = get_encoder_decoder(n_neurons, batch_norm)

    def forward(self, x):
        return self.decoder(self.encoder(x))

    def configure_optimizers(self):
        opt = torch.optim.Adam(self.parameters(), self.hparams['lr'])
        sched = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, factor=0.2 ,patience=20, verbose=True, min_lr=1e-6)
        scheduler = {'scheduler': sched, 'interval': 'epoch', 'monitor': 'val_checkpoint_on', 'reduce_on_plateau': True}
        return opt

    def shared_step(self, batch, batch_idx):
        bx, by = batch
        z = self.encoder(bx)
        out = self.decoder(z)
        loss = F.mse_loss(out, bx)
        bce_loss = F.binary_cross_entropy(torch.clamp(out, 1e-6, 1 - 1e-6), bx, reduction='mean')
        self.log('loss', loss)
        self.log('bce_loss', bce_loss)
        lmbda = 0.00
        reg = lmbda * (z**2).mean()
        self.log('regularization', reg)
        return bce_loss
    
    def training_step(self, batch, batch_idx):
        return self.shared_step(batch, batch_idx)

    def validation_step(self, batch, batch_idx):
        return self.shared_step(batch, batch_idx)

    def train_dataloader(self):
        dataset = MNIST("data", download=True, transform=transform)
        return DataLoader(dataset, batch_size=256, shuffle=True, num_workers=4)

    def val_dataloader(self):
        dataset = MNIST("data", download=True, transform=transform, train=False)
        return DataLoader(dataset, batch_size=256, shuffle=True, num_workers=4)

    def encode(self, batch):
        bx, by = batch
        return self.encoder(bx)

    def encode_ds(self, ds):
        dl = DataLoader(ds, batch_size=256, num_workers=4, shuffle=False)
        self.eval()
        encoded = []
        with torch.no_grad():
            for batch in dl:
                encoded.append(self.encode(batch).detach().cpu().numpy())
        return np.concatenate(encoded, axis=0)

    def cluster(self, ds, k=10):
        X = self.encode_ds(ds)
        kmeans = KMeans(k)
        return kmeans.fit_predict(X)

# # Commented out IPython magic to ensure Python compatibility.
# def normal_to_multivariate1(p):
#     return D.LowRankMultivariateNormal(p.mean, torch.zeros_like(p.mean[:1].T), p.stddev)

# def normal_to_multivariate2(p):
#     return D.MultivariateNormal(p.mean, covariance_matrix=torch.diag_embed(p.variance))

# def normal_to_multivariate3(p):
#     return D.MultivariateNormal(p.mean, scale_tril=torch.diag_embed(p.stddev))


# @D.register_kl(D.Normal, D.MultivariateNormal)
# def kl_normal_multivariateNormal(p, q):
#     p_lrmv =D.LowRankMultivariateNormal(p.mean, torch.zeros_like(p.loc.T), p.stddev)
#     return kl_divergence(p_lrmv, q)

# %timeit -n 100 normal_to_multivariate(dist)
# %timeit -n 100 normal_to_multivariate2(dist)
# %timeit -n 100 normal_to_multivariate3(dist)

#  = D.Independent(D.Normal(torch.randn(100, 5), torch.rand(100, 5) + 1), 1)
# d1 = D.LowRankMultivariateNormal(dist.mean, torch.zeros_like(dist.mean.T), cov_diag=dist.stddev)
# d2 = distD.MultivariateNormal(d1.loc + 1, covariance_matrix=d1.covariance_matrix)
# kl_divergence(d1, d2)

def normal_to_multivariate(p):
    return D.MultivariateNormal(p.mean, scale_tril=torch.diag_embed(p.stddev))

def cross_entropy(P, Q):
    try:
        return kl_divergence(P, Q) + P.entropy()
    except NotImplementedError:
        if type(P) == D.Independent and type(P.base_dist) == D.Normal:
            return kl_divergence(normal_to_multivariate(P), Q) + P.entropy()
        raise NotImplementedError

def cross_entropy_estimate(P, Q, k=100):
    samples = P.sample((k,))
    return - Q.log_prob(samples).mean()

def cross_entropy_normal(P, Q):
    return 0.5 * torch.log(2 * math.pi * Q.scale**2) + 0.5 * (P.scale / Q.scale)**2 + 0.5 * ((P.loc - Q.loc)/Q.scale)**2 


class LatentDistribution(nn.Module):
    prior = Normal(0, 1)
    def __init__(self, in_features, out_features, sigma=None, same_sigma=False):
        super(LatentDistribution, self).__init__()
        # self.multivariate = multivariate
        self.mu_fc = nn.Linear(in_features, out_features)
        if sigma:
            self.sigma = sigma
        else:
            if same_sigma:
                self.logvar_fc = nn.Linear(in_features, 1)
                self.logvar_fc.weight.data.zero_()
                self.logvar_fc.bias.data.zero_()
            else:
                self.logvar_fc = nn.Linear(in_features, out_features)
                self.logvar_fc.weight.data.zero_()
                self.logvar_fc.bias.data.zero_()
                # self.logvar_fc.bias.data -= 10.
        
    
    def forward(self, x):
        mu = self.mu_fc(x)
        if hasattr(self, 'sigma'):
            sigma = self.sigma
        else:
            logvar = self.logvar_fc(x)
            sigma = torch.exp(logvar / 2)
        self.dist = D.Independent(Normal(mu, sigma), 1)
        return self.dist
    
    def sample(self, l=1):
        return self.dist.rsample()

    def kl_loss(self, prior=None):
        if not prior:
            prior = self.prior
        return kl_divergence(self.dist, prior).sum(dim=-1)

class BernoulliDistribution(nn.Module):
    def __init__(self, in_features, out_features):
        super(BernoulliDistribution, self).__init__()
        self.probs = nn.Sequential(nn.Linear(in_features, out_features), nn.Sigmoid())
    
    def forward(self, x):
        self.dist = D.Bernoulli(probs=self.probs(x))
        return self.dist


from torch import autograd
from torch.utils.data import ConcatDataset, TensorDataset

transform = transforms.Compose([transforms.ToTensor(), 
                                transforms.Lambda(lambda x: torch.flatten(x))])

# def xlogx(x, eps=1e-12):
#     xlog = x * (x + eps).log()
#     # import pdb; pdb.set_trace()
#     return xlog

# def clustering_accuracy(gt, cluster_assignments):
#     mat = metrics.confusion_matrix(cluster_assignments, gt, labels=np.arange(max(max(gt), max(cluster_assignments)) + 1))
#     cluster_assignments = mat.argmax(axis=1)[cluster_assignments]
#     return metrics.accuracy_score(gt, cluster_assignments)

class VaDE(nn.Module):
    def __init__(self, n_neurons=[784, 512, 256, 10], batch_norm=True, k=10, lr=1e-3, device='cuda',
                 pretrain_model=None, init_gmm=None, logger=None, covariance_type=None, debug=True):
        super(VaDE, self).__init__()
        self.k = k
        self.log = logger
        self.n_neurons, self.batch_norm = n_neurons, batch_norm
        self.debug = debug
        self.hparams = {'lr': lr}
        self.hparams['covariance_type'] = covariance_type
        self.latent_dim = n_neurons[-1]
        self.mixture_logits = nn.Parameter(torch.zeros(k, device=device))
        self.mu_c = nn.Parameter(torch.zeros(k, self.latent_dim, device=device))
        if self.hparams['covariance_type'] == 'diag':
            self.sigma_c = nn.Parameter(torch.ones(k, self.latent_dim, device=device))
            self.gmm_params = [self.mixture_logits, self.mu_c, self.sigma_c]
        elif self.hparams['covariance_type'] == 'full':
            self.scale_tril_c = nn.Parameter(torch.eye(self.latent_dim).repeat((k, 1, 1)))
            self.gmm_params = [self.mixture_logits, self.mu_c, self.scale_tril_c]
        else:
            raise Exception(f"illigal covariance_type {covariance_type}, can only be 'full' or 'diag'")
        n_layers = len(n_neurons) - 1
        layers = list()
        for i in range(n_layers-1):
            layer = nn.Sequential(nn.Linear(n_neurons[i], n_neurons[i+1]),
                                  nn.ReLU(),
                                  nn.BatchNorm1d(n_neurons[i+1]) if batch_norm else nn.Identity())
            layer.register_forward_hook(self.register_stats(f"encoder_{i}"))
            layers.append(layer)
        self.encoder = nn.Sequential(*layers)
        self.latent_dist = LatentDistribution(n_neurons[-2], n_neurons[-1])
        
        self.latent_dist.mu_fc.register_forward_hook(self.register_stats(f"latent mu"))
        self.latent_dist.logvar_fc.register_forward_hook(self.register_stats(f"latent logvar"))
        layers = list()
        n_neurons = n_neurons[::-1]
        for i in range(n_layers-1):
            layers.append(nn.Sequential(nn.Linear(n_neurons[i], n_neurons[i+1]),
                                        nn.ReLU(),
                                        nn.BatchNorm1d(n_neurons[i+1]) if batch_norm else nn.Identity()))
        self.decoder = nn.Sequential(*layers)
        self.out_dist = BernoulliDistribution(n_neurons[-2], n_neurons[-1])
        self.model_params = list(self.encoder.parameters()) + list(self.latent_dist.parameters()) + \
                            list(self.decoder.parameters()) + list(self.out_dist.parameters())
        if pretrain_model is not None and init_gmm is not None:
            self.mixture_logits.data = torch.Tensor(np.log(init_gmm.weights_))
            self.mu_c.data = torch.Tensor(init_gmm.means_)
            if self.hparams['covariance_type'] == 'diag':
                self.sigma_c.data = torch.Tensor(init_gmm.covariances_).sqrt()
            elif self.hparams['covariance_type'] == 'full':
                self.scale_tril_c.data = torch.Tensor(np.linalg.inv(init_gmm.precisions_cholesky_).transpose((0, 2, 1)))
            self.encoder.load_state_dict(pretrain_model.encoder[:-1].state_dict())
            self.decoder.load_state_dict(pretrain_model.decoder[:-1].state_dict())
            self.latent_dist.mu_fc.load_state_dict(pretrain_model.encoder[-1].state_dict())
            self.out_dist.probs[0].load_state_dict(pretrain_model.decoder[-1][0].state_dict())
            
    def forward(self, bx):
        x = self.encoder(bx)
        z_dist = self.latent_dist(x)
        z = z_dist.rsample()
        x_dist = self.out_dist(self.decoder(z))
        return x_dist

    def register_stats(self, layer_name):
        def hook_fn(module, inputs, outputs):
            self.log(f"{layer_name} mean", inputs[0].mean())
            self.log(f"{layer_name} std", inputs[0].std(dim=0).mean())
        return hook_fn

    @property
    def component_distribution(self):
        if self.hparams['covariance_type'] == 'diag':
            return D.Independent(D.Normal(self.mu_c, self.sigma_c), 1)
        elif self.hparams['covariance_type'] == 'full':
            return D.MultivariateNormal(self.mu_c, scale_tril=self.scale_tril_c)

    def comp_dists(self, i):
        if self.hparams['covariance_type'] == 'diag':
            return D.Independent(D.Normal(self.mu_c[i], self.sigma_c[i]), 1)
        elif self.hparams['covariance_type'] == 'full':
            return  D.MultivariateNormal(self.mu_c[i], scale_tril=self.scale_tril_c[i])

    # comp_dists = property(comp_dists_)

    def shared_step(self, bx):
        x = self.encoder(bx)
        z_dist = self.latent_dist(x)
        if self.debug and z_dist.stddev.max() > 100:
            import pdb; pdb.set_trace()
        self.log("latent dist std", z_dist.stddev.mean().detach())
        z = z_dist.rsample()
        decoded = self.decoder(z)
        x_dist = self.out_dist(decoded)
        x_recon_loss = - x_dist.log_prob(bx).sum(dim=-1)
        bce_loss = F.binary_cross_entropy_with_logits(self.out_dist.probs[0](decoded), bx)
        ###################################
        
        log_p_z_c = self.component_distribution.log_prob(z.unsqueeze(1))
        log_q_c_z = torch.log_softmax(log_p_z_c + self.mixture_logits, dim=-1)  # dims: (bs, k)
        q_c_z = log_q_c_z.exp()
        cross_entropies = torch.stack([cross_entropy(z_dist, self.comp_dists(i)) for i in range(self.k)], dim=-1)
        ent_loss1 = z_dist.entropy()
        # + E_q(z,c|x) [log p(z|c)]:
        crosent_loss1 = - (cross_entropies * q_c_z).sum(dim=-1)
        # + E_q(z,c|x) [log p(c)]:
        crosent_loss2 = (q_c_z * (self.mixture_logits.softmax(dim=0)[None] + 1e-9).log()).sum(dim=-1)
        # - Eq(z,c|x) [log q(c|x)]:
        ent_loss2 = - (q_c_z * log_q_c_z).sum(dim=-1)
        # ent_loss2 = - xlogx(q_c_z).sum(dim=-1)

        self.log('ent_loss1', - ent_loss1.mean(), logger=True)
        self.log('crosent_loss1', - crosent_loss1.mean(), logger=True)
        self.log('ent_loss2', - ent_loss2.mean(), logger=True)
        self.log('crosent_loss2', - crosent_loss2.mean(), logger=True)
        # self.log('gmm likelihood', - gmm.log_prob(z).mean())

        ############################################################################
        kl_loss = - crosent_loss1 - crosent_loss2 - ent_loss1 - ent_loss2
        loss = x_recon_loss + kl_loss

        if self.debug and loss.isnan().any():
            import pdb; pdb.set_trace()
        return loss.mean(), x_recon_loss.mean(), kl_loss.mean(), bce_loss.mean()

    def cluster_data(self, dl=None):
        self.eval()
        gt, labels, X_encoded = [], [], []
        with torch.no_grad():
            for bx, by in dl:
                x_encoded = self.latent_dist(self.encoder(bx.cuda())).mean
                X_encoded.append(x_encoded)
                gt.append(by)
                log_p_z_given_c = self.component_distribution.log_prob(x_encoded.unsqueeze(1))
                labels.append((log_p_z_given_c + self.mixture_logits).softmax(dim=-1).argmax(dim=-1))
        gt = torch.cat(gt).cpu().numpy()
        labels = torch.cat(labels).cpu().numpy()
        X_encoded = torch.cat(X_encoded).cpu().numpy()
        return gt, labels, X_encoded


class MNISTDataModule(pl.LightningDataModule):
    def __init__(self, batch_size):
        super().__init__()
        self.batch_size = batch_size

    def prepare_data(self):
        train_ds = MNIST("data", download=True)
        valid_ds = MNIST("data", download=True, train=False)

    def setup(self, stage=None):
        train_ds = MNIST("data", download=True)
        valid_ds = MNIST("data", download=True, train=False)
        to_tensor_dataset = lambda ds: TensorDataset(ds.data.view(-1, 28**2).float()/255., ds.targets)
        self.train_ds, self.valid_ds = map(to_tensor_dataset, [train_ds, valid_ds])
        self.all_ds = ConcatDataset([self.train_ds, self.valid_ds])

    def train_dataloader(self):
        return DataLoader(self.train_ds, batch_size=self.batch_size, shuffle=True, num_workers=8)

    def val_dataloader(self):
        return DataLoader(self.valid_ds, batch_size=1024, shuffle=False, num_workers=8)

    def all_dataloader(self):
        return DataLoader(self.all_ds, batch_size=1024, shuffle=False, num_workers=8)


class PLVaDE(pl.LightningModule):
    def __init__(self, n_neurons=[784, 512, 256, 10], batch_norm=True, k=10, lr=1e-3, 
                 device='cuda', pretrain_epochs=50, covariance_type='full', batch_size=2**8,
                 data_size=None, debug=True):
        super(PLVaDE, self).__init__()
        self.save_hyperparameters()
        # self.hparams = {'lr': lr, 'full_cov': full_cov}
        pretrain_model, init_gmm = self.init_params(n_neurons, batch_norm, k, pretrain_epochs)
        self.pretrained_model, self.init_gmm = pretrain_model, init_gmm
        self.model = VaDE(n_neurons=n_neurons, batch_norm=batch_norm, k=k, device=device, debug=debug,
                          covariance_type=covariance_type, pretrain_model=pretrain_model, init_gmm=init_gmm, logger=self.log)
        

    def prepare_data(self):
        train_ds = MNIST("data", download=True)
        valid_ds = MNIST("data", download=True, train=False)
        to_tensor_dataset = lambda ds: TensorDataset(ds.data.view(-1, 28**2).float()/255., ds.targets)
        self.train_ds, self.valid_ds = map(to_tensor_dataset, [train_ds, valid_ds])
        if self.hparams['data_size'] is not None:
            n_sample = self.hparams['data_size']
            to_subset = lambda ds: torch.utils.data.random_split(ds, 
                                                                 [n_sample, len(ds) - n_sample],
                                                                 torch.Generator().manual_seed(42))[0]
            self.train_ds, self.valid_ds = map(to_subset, [self.train_ds, self.valid_ds])
        self.all_ds = ConcatDataset([self.train_ds, self.valid_ds])

    def init_params(self, n_neurons, batch_norm, k, pretrain_epochs):
        self.prepare_data()
        pretrain_model = SimpleAutoencoder(n_neurons, batch_norm=batch_norm, lr=3e-4)
        pretrain_model.val_dataloader = self.val_dataloader
        pretrain_model.train_dataloader = self.train_dataloader
        trainer = pl.Trainer(gpus=1, max_epochs=pretrain_epochs, progress_bar_refresh_rate=10)
        trainer.fit(pretrain_model)
        dataset = MNIST("data", download=True, transform=transform)
        X_encoded = pretrain_model.encode_ds(dataset)
        init_gmm = GaussianMixture(k, covariance_type=self.hparams['covariance_type'], n_init=3)
        init_gmm.fit(X_encoded)
        return pretrain_model, init_gmm
        
    def train_dataloader(self):
        return DataLoader(self.train_ds, batch_size=self.hparams['batch_size'], shuffle=True, num_workers=8)

    def val_dataloader(self):
        return DataLoader(self.valid_ds, batch_size=1024, shuffle=False, num_workers=8)

    def configure_optimizers(self):
        opt = torch.optim.AdamW(
            [{'params': self.model.model_params}, 
             {'params': self.model.gmm_params, 'lr': self.hparams['lr']}], 
            self.hparams['lr'], weight_decay=0.00)
        sched = torch.optim.lr_scheduler.LambdaLR(opt, lambda epoch: (epoch+1)/10 if epoch < 10 else 0.9**(epoch//10 - 1))
        return [opt], [sched]
    
    def training_step(self, batch, batch_idx):
        bx, by = batch
        loss, rec_loss, kl_loss, bce_loss = self.model.shared_step(bx)
        result = {'loss': loss, 
                  'rec_loss': rec_loss.detach(),
                  'kl_loss': kl_loss.detach(),
                  'bce_loss': bce_loss.detach()}
        for k, v in result.items():
            self.log(k, v, logger=True)
        return result

    def validation_step(self, batch, batch_idx):
        bx, by = batch
        loss, rec_loss, kl_loss, bce_loss = self.model.shared_step(bx)
        result = {'loss': loss.detach(), 
                  'rec_loss': rec_loss.detach(),
                  'kl_loss': kl_loss.detach(),
                  'bce_loss': bce_loss.detach()}
        for k, v in result.items():
            self.log(k, v, logger=True)
        return result

    def cluster_data(self, dl=None):
        if not dl:
            dl = DataLoader(self.all_ds, batch_size=1024, shuffle=False, num_workers=4)
        return self.model.cluster_data(dl)

from pytorch_lightning.callbacks import Callback
from scipy.optimize import linear_sum_assignment as linear_assignment


def clustering_accuracy(gt, cluster_assignments):
    mat = metrics.confusion_matrix(cluster_assignments, gt, labels=np.arange(max(max(gt), max(cluster_assignments)) + 1))
    cluster_assignments = mat.argmax(axis=1)[cluster_assignments]
    return metrics.accuracy_score(gt, cluster_assignments)


def cluster_acc(Y_pred, Y):
    # from sklearn.utils. import linear_assignment
    assert Y_pred.shape == Y.shape
    D = max(Y_pred.max(), Y.max())+1
    w = np.zeros((D,D), dtype=np.int64)
    for i in range(Y_pred.size):
        w[Y_pred[i], Y[i]] += 1
    ind = linear_assignment(w.max() - w)
    return sum([w[i,j] for i,j in zip(*ind)])*1.0/Y_pred.size


class ClusteringEvaluationCallback(Callback):
    def __init__(self):
        super(ClusteringEvaluationCallback, self).__init__()

    def on_epoch_start(self, trainer, pl_module):
        gt, labels, _ = pl_module.cluster_data()
        nmi, acc2 = metrics.normalized_mutual_info_score(labels, gt), clustering_accuracy(gt, labels)
        acc3 = cluster_acc(labels, gt)
        ari = metrics.adjusted_rand_score(gt, labels)
        pl_module.log('NMI', nmi, on_epoch=True)
        pl_module.log('ARI', ari, on_epoch=True)
        pl_module.log('ACC2', acc2, on_epoch=True)
        pl_module.log('ACC', acc3, on_epoch=True)

sweep_config = {
    "method": "random",
    "project": "VADE",
    "metric": {
        "name": "ACC", 
        "goal": "maximize"
    },
    "parameters": {
        "n_last_layer": {"values": [2048]},
        "data_size": {"values": [1024]},
        "batch_size": {
            "distribution": "q_log_uniform",
            "min": 32,
            "max": 256,
            "q": 32
        },
        "pretrain_epochs": {
            "values": [30, 50, 70]
        },
        "covariance_type": {
            "values": ["full", "diag"]
        },
        "training_epochs": {"values": [16]},
        "learning_rate": {
            "distribution": "log_uniform",
            "min": -9.21,
            "max": -4.61
        }
    }
}

import wandb
# sweep_id = wandb.sweep(sweep_config, project="VADE")
sweep_id = "trqzdwn9"

def sweep_iteration():
    wandb.init()
    logger = pl.loggers.WandbLogger()
    vade = PLVaDE(n_neurons=[784, 512, 512, wandb.config.n_last_layer, 10], 
                  k=10, 
                  lr=wandb.config.learning_rate, 
                  batch_norm=False, 
                  pretrain_epochs=wandb.config.pretrain_epochs, 
                  covariance_type=wandb.config.covariance_type, 
                  data_size=wandb.config.data_size, 
                  batch_size=wandb.config.batch_size,
                  debug=False)
    
    trainer = pl.Trainer(gpus=1, logger=logger, max_epochs=wandb.config.training_epochs, 
                        callbacks=[ClusteringEvaluationCallback()])
    
    trainer.fit(vade)


wandb.agent(sweep_id, project="VADE", function=sweep_iteration, count=30)